%introduction.tex%
% Introduction %

\section{Introduction}
%The goal of theoretical chemistry is to further develop mathematics and computational algorithms to predict the accurate properties of chemical systems using the quantum mechanical nature of electrons.  
A grand challenge of theoretical chemistry is to be able to predict accurate properties of chemical systems from the first principles of quantum mechanics. This challenge has many front:  solving increasingly large systems at low cost, predicting chemical properties and finding transition structures to name a few. The electronic and nuclear structure of a chemical system is described by a many body differential equation using Hamiltonian mechanics, known as the Schr{\"o}dinger.  Solving this equation, analytically, in its raw form for non-trivial systems is too difficult. To model chemical systems, therefore, requires mathematical approximations starting from the first principles of quantum mechanics which can accurately approximate solutions to the Schr{\"o}dinger equation.  There exists a number of approximate methods such as Hartree Fock, coupled cluster, and density functional theory which calculate approximate solutions in a balance between computational effort and time, accuracy and chemical system size.
%Therefore, to model chemical systems, physics casts them into a many-body integro-differential equation known as the many-body Schr{\"o}dinger equation.
%The challenge comes from the rigorous mathematics 
%Achieving this goal will push computational analysis to the forefront of investigative research in chemistry reducing the time required to find a chemical for a specific application.  To successfully predict properties of chemicals and reactions, accuracy to an extremely small degree is required in computational chemistry\cite{Shavitt1977}
%Accuracy to an extremely small degree is important to correctly predict the small energy differences in electronic states or different geometries.
%Therefore, it is the task of theoretical chemistry is to provide an approximate framework which preserves the physical nature and accuracy of the exact model. 
%There exists a number of methods applicable to different systems depending on the user's interest to balance computational effort and time, accuracy, and chemical system size. 

%The gold standard in computational chemistry  the coupled cluster methods which are typically used to calculate ground state calculations but require the most computational resources and time. 
Hartree-Fock theory is a mean field approximation which provides a foundation to electronic correlation methods. Hartree-Fock thoery's perturbation based extensions, such as M{\/o}ller-Plesset theory, can be used to calculate electron correlation of molecules with around 100 atoms.  The coupled cluster methods, which are sometimes referred to as the gold standard of electronic structure calculations for their ability to calculate accurate electron correlation energy, require the most computational resources restricting it's calculation ability to molecules with 20-30 atoms. The goal of this research expand the scope of these methods through understanding and manipulation of their computational storage objects, tensors.   %are typically used to calculate energy of molecules with 20-30 atoms.
%Hartree-Fock and its perturbation based extensions such as M{\/o}ller-Plesset methods can recover some electron correlation and can be extended to molecules with around 100 atoms. Other methods such as density functional theory and semi-empirical methods based on classical mechanics can solve even larger molecules though their accuracy can be poor. Other methods such as density functional theory based on classical mechanics can solve even larger molecules though their accuracy can be poor.

In the computation of ab initio quantum mechanics, tensor storage, mutation and contraction are major bottlenecks. The term {\em curse of dimensionality}, first introduced by Bellman\cite{Chen2009} in the field of dynamic programming, refers to the exponential growth in operations required to estimate a function at some accuracy as the number of inputs increases. Using standard, non-decomposed, tensors in the formulation of quantum chemistry calculations is sub-optimal and falls victim to the curse of dimensionality.  Quantum chemists has developed methods which take advantage mathematical tensor structure and the physics which describes the data stored.  Methods such as 
%exponential increase in number of operations required to estimate a function at some accuracy as the number of inputs
%In the formulation of methods described above a major bottleneck is 
%Computational analysis using any one of these methods requires the storage and computation of many index vectors known as tensors.  Tensor storage, manipulation and contraction make up the majority of the bottleneck in the calculation of ab initio quantum chemistry.  In the world of mathematics this is known as the curse of dimensionality.  Though it also known that as dimensionality of tensor storage increases so does sparsity in the full representation of such tensors.  Quantum chemistry has developed methods in order to take advantage of the underlying structure of these tensors, such as projected atomic orbitals, pair natural orbitals and density fitting.  In general these methods reduce computational effort by arbitrarily reducing dimension using some canonical matrix decomposition.  The area of utilizing tensor decomposition in the realm of these physical approximations is sparsely investigated with only the recent introduction of tensor hypercontraction.  Using fast tensor decomposition of physical variables over modern computational architectures can provide data compression without loss of information.  Additionally, as theoretical chemistry pushes to calculate systems to analytical levels of accuracy, such as introduction of explicitly correlated methods, algorithms with extremely large computational scaling factors have developed.  Utilizing the form of tensor decompositions new algorithms can be developed which reduce exponential scaling factors by separating subspaces spanned in the tensor space.

%while reducing mathematical complexity